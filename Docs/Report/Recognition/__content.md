[**HOME**](/README.md)

# 영상 인식 - 개요

영상 인식 구현 문서

## 당구대 인식

당구대의 쿠션 외각 4개 점을 HSL 색공간에서의 간단한 필터링을 통해 획득하고, 이들로부터 원점에 위치한 당구대에 대한 Perspective Transform을 계산합니다. 계산된 트랜스폼은 카메라 원점으로부터 당구대 평면 노멀의 상대 트랜스폼이 됩니다. 특히, 오큘러스 리프트는 정교한 헤드 트래킹 방법을 제공하기 때문에, 1차적으로 당구대의 위치를 계산한 이후에는 간헐적으로 오차 보정만 수행하고, 오큘러스 리프트의 트래킹에 당구대의 위치를 의존합니다.

간단한 2D 기반 영상 인식 방법이지만, 퍼포먼스가 우수하고 구현이 간단하므로 최우선적으로 도입합니다.

## 당구공 인식


당구공은 단순한 구체이기 때문에 스크린 상에서 간단하게 검출할 수 있지만, 실제로 당구공이 표면에 접한 위치를 찾아내는 것은 꽤 까다로운 일입니다. 깊이 맵 상에서, 당구공 표면의 중점에 대한 정확한 상대 좌표를 알 수 있다면 당구공의 반지름만큼을 카메라 바깥 방향으로 투사해 당구공 구체의 중점을 구하고, 이를 다시 당구대의 법선 역방향으로 투사해 평면에 대한 구의 접점을 구할 수 있습니다.

![](2020-08-03-22-23-02.png)

다만, ZED M 깊이 카메라로부터 획득한 포인트 클라우드의 노이즈가 예상보다 심하다는 게 문제인데, 이 부분은 차차 해결해 나가야 할 것으로 보입니다.

## 큐대 인식

사실상 가장 까다로운 부분인데, 일단 당구공의 포즈는 정적이기 때문에 point cloud상에서 registration을 통해 transform을 추출해내는 방법을 고려하고 있습니다.

# 구현

아래 일지를 참조해주세요. 

# 일지

## 200804-1130

OpenCV와 ZED SDK, CUDA Toolkit등을 설치 완료하고, 빌드 환경을 구성했습니다.

## 200804-1530

![](2020-08-04-18-51-32.png)

카메라 연결 성공, ZED SDK 내부 데이터 형식인 sl::Mat을 cv::Mat으로 컨버팅하고 cv::imshow 함수를 통해 디스플레이

## 200804-1630

당구대, 당구공 등의 물체는 강한 원색을 띠므로, HSL 색공간으로 전환하고 Hue만을 도출하여 각 물체의 윤곽선을 검출하고자 합니다.

![](2020-08-04-18-52-56.png)

HSL 색공간으로 데이터를 표현하자 당구대의 네 귀퉁이가 선명하게 드러납니다. 그러나 벽면을 보면, Lightness가 높은 흰색 물체라 Hue값의 의미가 없음에도 불구하고 Hue가 보라색으로 잡히고, 검은색 받침대는 파란색이 잡힙니다.

![](2020-08-04-18-54-09.png)

이는 Saturation값만을 표현한 이미지로, 벽면의 Saturation이 정상적으로 연하게 잡히는 것을 확인할 수 있습니다. Hue 값이 0으로 고정되어 있기 때문에 이미지는 전반적으로 파란 톤을 띱니다.

널브러진 흰 티나 당구대의 음영 부분의 Saturation도 100%가 잡히는 문제가 있는데, 이는 Lightness가 0% 또는 100%일 때 Saturation이 100%로 고정되면서 발생하는 문제로, 향후 Lightness가 극단적인 수치를 갖는 픽셀의 Saturation을 0으로 설정하는 처리를 수행할 예정입니다.

![](2020-08-04-18-55-40.png)

이는 Saturation과 Hue를 결합한 이미지로, 한 눈에 보기에도 다른 곳에 비해 당구대의 색감이 강하게 드러납니다. 이 상태에서 Hue를 당구대 색상으로 필터링하면 당구대의 영역을 구할 수 있을 것으로 보입니다.

## 200804-1900

HSL 색공간은 Hue의 cyclic한 특성으로 인해 OpenCV의 내장 필터링 함수(Threshold)로 필터링을 수행하기가 다소 난해합니다. 만약 HSI 채널의 Saturation과 Hue 값을 사용한다면, 이는 사실 YUV, Lab처럼 밝기를 별도의 채널로 빼낸 색공간에서 밝기 채널을 고정시키는 것과 같은 효과이므로, 이들 방법 또한 시도해봅니다.

![](2020-08-04-19-34-12.png)

YUV 색공간에서 Y값을 고정한 이미지로, 각 엘리먼트의 색상을 꽤 명료하게 잡아내지만 당구대의 바깥틀에 가려진 음영 부위의 식별이 다소 모호합니다. 

> ![](2020-08-04-19-40-04.png)
> <br> FIX: OpenCV에서 따르는 HSL 모델은 위와 같으며, 따라서 Hue는 딱히 cyclic하지 않습니다. 
> <br> YUV의 퍼포먼스가 그다지 뛰어나지 못하다는 것도 확인했으므로, 원래대로 HSL 색공간을 활용합니다.

## 200804-2200

![](2020-08-04-22-00-28.png)

HSL 색공간에서 HSL 값 각각에 대해, $H=[0, 35], S=[180,250], V=[20, 230]$의 값으로 필터링을 수행한 결과입니다.

![](2020-08-04-22-01-28.png)

그러나 카메라의 자동 노출에 꽤 취약합니다.

## 200804-2230

![](2020-08-04-22-10-11.png)

앞서 언급된 자동 노출 문제는, 사실은 [200804-1900](##200804-1900)에서 언급된 Hue의 Cyclic한 특성으로 인한 것으로 판단됩니다. 필터를 낮 은레벨, 높은 레벨 두 번에 걸쳐 걸자 정상적으로 당구대 영역이 검출되었습니다.

![](2020-08-04-22-18-02.png)

앞서 검출된 영역을 원본 이미지와 합성한 결과로, 단순히 마스크를 시각화합니다. 위에서 하늘색 이불이 잘못 필터링되는 문제가 있는데, 이는 차후 다른 색공간에서의 필터링 작업을 통해 교정할 예정입니다.

이 과정까지의 소모 시간은 약 5ms 안팎으로, 1초에 30프레임을 목표로 삼았을 때(33ms per frame) 제법 여유가 있는 수준입니다.

![](2020-08-04-22-25-06.png)

필터 값의 조정을 통해서도 영역의 검출이 가능하지만, 당구대 자체의 영역이 침식되는 문제가 있습니다. 

## 20200804-2230

![](2020-08-04-22-35-33.png)

YUV 색상 기반의 필터입니다. 훨씬 깔끔하게 동작하고, 동작 속도도 20% 개선됩니다. (1ms 단축)

![](2020-08-04-22-48-41.png)
![](2020-08-04-22-40-20.png)

이렇게 생성된 마스크에 침식(cv::erode)과 팽창(cv::dilate) 연산을 반복적으로(iterations:25) 적용한 결과입니다. 당구대 영역이 거의 완벽하게 검출됩니다. 

이 과정에서 추가되는 연산량은 약 1.5ms정도로, 결과물의 품질을 고려하면 꽤 합리적입니다.

![](2020-08-04-22-49-00.png)
![](2020-08-04-22-42-16.png)

단, 팽창-침식 연산 자체의 물리적 한계로 당구대의 바운드가 경계면에 다가갈 경우 위 이미지와 같이 마스크가 비정상적으로 팽창됩니다. 

하지만 당구대의 트랜스폼 검출 정보는 최초 1회만 수행되고, 이후에는 오류 검출을 위해 confidence가 아주 높을 때에만 위치 보정을 위해 부차적으로 활용되며, 따라서 이미지에서 당구대의 ROI rectangle만 추려낼 수 있다면 반복적인 침식-팽창 연산으로 인한 glitch는 무시할 수 있는 수준입니다.

> 당구대 ROI는 연산 최적화를 위해 고려합니다. 체감상 영상 처리 알고리즘의 퍼포먼스에는 해상도가 미치는 영향이 가장 지배적이었습니다.

## 20200804-2300

> NOTE: 현재 Stereo camera의 이미지 중 좌안의 이미지만 활용하고 있는데, 향후 좌안 카메라의 이미지로부터 당구대의 정확한 트랜스폼을 구할 수 있다면, 단순히 좌안 카메라를 상대 좌표계의 원점으로 삼고, 우안 카메라의 원점을 오프셋 시킴으로써 좌안 카메라로부터 검출된 트랜스폼 정보를 우안 카메라에 동기시킬 수 있을 것으로 보입니다. 
>
> 아직까지는 확정된 것이 없기 때문에, 일단 아이디어로써 적어둡니다.

## 20200805-1100

![](2020-08-05-11-17-29.png)

컬러 이미지에 검출된 당구대 영역을 ZED의 스테레오 카메라로부터 도출된 깊이 맵 정보로 오버레이한 모습입니다. 

![](2020-08-05-11-27-17.png)

당구대 도형의 네 contour의 정확한 위치 좌표를 알 수 있다면 가장 이상적인 방법으로 정확한 당구대의 위치를 추론할 수 있겠으나, 위 그림과 같이 깊이 맵을 오버레이한 경우 깊이 맵과 컬러 이미지 사이에 꽤 큰 오프셋이 보입니다.

당구공은 거의 통째로 옆으로 옮겨 놓은 수준이라, 실제 활용이 다소 어려워 보입니다.

## 20200805-1130

![](2020-08-05-11-31-37.png)

설정 상에 다소 오류가 있었는데, 깊이 이미지와 컬러 이미지 모두 좌안 기준으로 생성되게 함으로써 매칭 이슈가 해결되었습니다. 

여기까지 걸린 전체 프로세스는 약 60 ms 내외로, 깊이 이미지와 컬러 이미지 두 매를 retrieve하면서 퍼포먼스가 굉장히 떨어지게 되었는데, GPU 사용률은 30% 안쪽이고, CPU는 코어 하나만 죽도록 갈구는 상황으로 보입니다.

![](2020-08-05-11-39-40.png)

특히 zed 카메라로부터 이미지를 획득하는 코드의 부하가 높았습니다. 추후 이 구간이 퍼포먼스에 큰 병목이 될 경우, 한 프레임정도의 딜레이를 감수하고 별도의 스레드로 캡처 코드를 빼내는 편이 나을 듯합니다.

![](2020-08-05-11-42-12.png)

나머지 병목은 대부분 UMat을 활용하지 못하는 함수나 UMat-Mat 사이에 데이터를 전송하는 부분에서 발생했습니다. 이 부분의 최적화는 알고리즘을 어느 정도 다듬은 후, 천천히 고민해볼 문제로 보입니다.

> 현재 CPU 코어가 하나만 돌아가고 있는데, WITH_TBB, WITH_OpenMP 등의 플래그를 활성화한 opencv 빌드를 사용해 퍼포먼스를 개선할 수 있을 것으로 보입니다.

## 20200805-1200

![](2020-08-05-12-01-33.png)

이미 필터링을 통해 당구대 영역을 바이너리 마스크의 형태로 구한 상태이므로, 단순히 1회 침식한 이미지를 마스크에서 빼줌으로써 간단하게 경계선을 구할 수 있습니다. 

![](2020-08-05-14-00-00.png)

컨벡스 헐 연산을 통해 당구대 영역을 비교적 정확하게 검출할 수 있습니다. 

![](2020-08-05-14-28-42.png)

Contour 개수가 지나치게 많이 잡히는 문제는 apporxPolyDP 함수에 큰 epsilon값을 인자로 주어 해결할 수 있었습니다. 

![](2020-08-05-14-34-36.png)

위 이미지를 보면 여러 거짓 셰이프가 잡히는 것을 볼 수 있는데, 이를 셰이프의 면적과 contour 개수로 필터링합니다.




