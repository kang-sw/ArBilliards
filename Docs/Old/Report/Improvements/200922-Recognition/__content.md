- [인식 성능 개선](#인식-성능-개선)
  - [개요](#개요)
  - [절차](#절차)

# 인식 성능 개선

현재 인식 프로그램은 테이블의 네 귀퉁이 전체가 시야에 들어올 때만 테이블의 위치를 추정합니다. 그러나 당구를 칠 땐 몸을 앞으로 기울여 테이블의 일부만 시야에 들어오는 경우가 훨씬 많으므로, 이 상황에서도 당구대의 위치를 파악할 수 있도록 알고리즘을 개선합니다.

## 개요

현재 당구대 탐색 알고리즘은 이미지에서 모든 파란색 영역의 convex hull을 구하고, 그 중에서 정점의 개수가 4개인 contour 중 가장 큰 candidate를 선택해 해당 점에 `solvePnP` 함수를 적용, 3D 포즈를 계산합니다. 이후 해당 포즈를 다시 화면에 투영하여 오차가 일정 이하면 올바른 위치로 판단하는 식입니다.

`solvePnP`를 적용하는 이 방법은 강체(rigid body) 정점을 알아야 하는데, 당구대의 일부만 시야에 들어오면 시야 내의 당구대 영역 contour에 기하학적 변형이 생기는 만큼 위 방법을 그대로 적용하기는 어렵습니다.

그래서, `solvePnP` 함수와 유사한 역할을 수행하는 로직을 직접 작성해보기로 했습니다. 이미 당구공 인식에서 random iteration 방법에 대한 감을 조금 익혔기 때문에, 테이블의 이미 알려진 위치에서 시작해 random한 방향으로 translation, orientation의 탐색을 점점 좁혀나가는 방법을 사용해볼 생각입니다.

## 절차

1. 테이블의 파란 영역 contour중 크기가 가장 큰 후보를 선택합니다.
2. 해당 영역의 convex Hull을 획득합니다.
3. 정점 목록을 획득합니다.
4. 시작 트랜스폼은 당구대의 보고된 마지막 위치로 설정합니다.
5. 아래 과정을 정해진 횟수 또는 오차가 임계 이하에 도달할 때까지 반복합니다.
   1. 시작 트랜스폼에서 당구대를 화면에 투영합니다.  
     이 경우 해당 트랜스폼의 당구대가 화면 상에 어떻게 그려질지 정점 목록을 획득할 수 있습니다. 특히, 시야 밖으로 벗어난 부분은 시야 사각뿔 컬링에 의해 잘려나가므로, 어느 시점에는 반드시 화면 상의 테이블 정점과 추정된 위치에서 투영된 테이블의 정점이 일치해야 합니다.
   2. 투영된 컨투어의 정점 개수가 이미지 컨투어의 정점 개수가 일치하지 않으면 discard.
   3. 오차를 계산합니다. 이 때 순서는 보장되지 않으므로, 정점 목록을 한 자리씩 rotate하며 가장 작은 오차가 계산되는 값을 그 estimation의 오차로 사용합니다.
   4. 오차가 가장 작은 점을 시작 트랜스폼으로 정합니다.
   5. 반복
